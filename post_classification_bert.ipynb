{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import mysqlDatabase\n",
    "from myBertTools import myBertModel, myTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_data(MysqlDatabase, sql):\n",
    "    df = MysqlDatabase.select_table(sql)\n",
    "    df['text'] = df['title'] + ' ' + df['excerpt'] + ' ' + df['topics']\n",
    "    df = df[['text', 'name']]\n",
    "    df.columns = ['text', 'label']\n",
    "    ##\n",
    "    df_t, df_v,= train_test_split(df, test_size = 0.1, random_state = 42, stratify = df.label)\n",
    "    df_t['type'] = 'train'\n",
    "    df_v['type'] = 'valid'\n",
    "    df = pd.concat([df_t, df_v], sort=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # 標籤存檔\n",
    "    label_df = pd.get_dummies(df.label)\n",
    "    Y = label_df.values\n",
    "    print('Shape of label tensor:', Y.shape)\n",
    "\n",
    "    label_list = list(label_df.columns)\n",
    "    label_dic = { i : label_list[i] for i in range(0, len(label_list) ) }\n",
    "    label_site = './model_output/dcard_cate_label_dic.npy'\n",
    "    np.save(label_site, label_dic)\n",
    "\n",
    "    ##\n",
    "    Y_df = pd.DataFrame(Y)\n",
    "    df = pd.concat([df, Y_df],sort = True, axis=1)\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "    return df, Y_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def seq_padding(X, padding=0):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    return np.array([\n",
    "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class dataGenerator:\n",
    "    def __init__(self, data, batch_size=32):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    "            np.random.shuffle(idxs)\n",
    "            X1, X2, Y = [], [], []\n",
    "            for i in idxs:\n",
    "                d = self.data[i]\n",
    "                text = d[0][:maxlen]\n",
    "                x1, x2 = MyTokenizer.encode(first=text)\n",
    "                y = d[1:]\n",
    "                X1.append(x1)\n",
    "                X2.append(x2)\n",
    "                Y.append(y)\n",
    "                if len(X1) == self.batch_size or i == idxs[-1]:\n",
    "                    X1 = seq_padding(X1)\n",
    "                    X2 = seq_padding(X2)\n",
    "                    Y = seq_padding(Y)\n",
    "                    yield [X1, X2], Y\n",
    "                    [X1, X2, Y] = [], [], []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ['TF_KERAS'] = '1'\n",
    "    maxlen = 100\n",
    "    pretrained_path = '/Users/jackyfu/Desktop/hwf87_git/bert_wwm/'\n",
    "    config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "    checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "    vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "    output_path = '/Users/jackyfu/Desktop/hwf87_git/Dcard_post_classification/model_output'\n",
    "    with open('config.yml', 'r') as stream:\n",
    "        myconfig = yaml.load(stream, Loader=yaml.CLoader)\n",
    "    database_username = myconfig['mysql_database']['database_username']\n",
    "    database_password = myconfig['mysql_database']['database_password']\n",
    "    database_ip       = myconfig['mysql_database']['database_ip']\n",
    "    database_name     = myconfig['mysql_database']['database_name']\n",
    "    MysqlDatabase = mysqlDatabase(database_username, database_password, database_ip, database_name)\n",
    "    sql = '''\n",
    "    SELECT df.name, dp.*\n",
    "    FROM Bigdata.dcard_posts dp\n",
    "    left join Bigdata.dcard_forums df on dp.forumid = df.id\n",
    "    WHERE 1=1\n",
    "    and df.name in ('時事', '網路購物', '股票', '美妝', '工作', '考試', '穿搭', '3C', 'Apple', '感情', \n",
    "                    '美食', '理財', '居家生活', '臺灣大學', 'YouTuber');\n",
    "    '''\n",
    "    ##\n",
    "    df, Y_df = get_data(MysqlDatabase, sql)\n",
    "    MyBertModel = myBertModel(pretrained_path, config_path, checkpoint_path, vocab_path)\n",
    "    token_dict = MyBertModel.get_token_dict()\n",
    "    model = MyBertModel.build_model(Y_df)\n",
    "    MyTokenizer = myTokenizer(token_dict)\n",
    "\n",
    "    train_data = df[df['type'] == 'train'].drop(columns=['label', 'type']).values.tolist()\n",
    "    valid_data = df[df['type'] == 'valid'].drop(columns=['label', 'type']).values.tolist()\n",
    "    \n",
    "    train_D = dataGenerator(train_data)\n",
    "    valid_D = dataGenerator(valid_data)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_D.__iter__(),\n",
    "        steps_per_epoch=len(train_D),\n",
    "        epochs=2,\n",
    "        validation_data=valid_D.__iter__(),\n",
    "        validation_steps=len(valid_D)\n",
    "    )\n",
    "    model_path = './model_output/dcard_post_cls_bert.h5'\n",
    "    model.save(model_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully select from Bigdata table\n",
      "Shape of label tensor: (9134, 15)\n",
      "(9134, 18)\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/17/dsyzw2j96ggfgmrjcsnbtz700000gn/T/ipykernel_57338/1431389716.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_t['type'] = 'train'\n",
      "/var/folders/17/dsyzw2j96ggfgmrjcsnbtz700000gn/T/ipykernel_57338/1431389716.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_v['type'] = 'valid'\n",
      "2021-09-04 17:20:55.718164: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-04 17:20:55.718239: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, None, 768)    101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 768)          0           model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 15)           11535       lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 101,688,591\n",
      "Trainable params: 101,688,591\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-04 17:20:58.811399: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-04 17:20:58.811571: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-09-04 17:21:03.128197: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "257/257 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.7156"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-04 17:32:06.573084: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "257/257 [==============================] - 696s 3s/step - loss: 0.1104 - accuracy: 0.7156 - val_loss: 0.0557 - val_accuracy: 0.8676\n",
      "Epoch 2/2\n",
      "257/257 [==============================] - 1061s 4s/step - loss: 0.0435 - accuracy: 0.8978 - val_loss: 0.0477 - val_accuracy: 0.8753\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/jackyfu/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "0729e0afaf4d65e2a91a3bdab3b4bf083879cf81e41f52fbed812722fa13cb93"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}