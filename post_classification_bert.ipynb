{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import mysqlDatabase\n",
    "from myBertTools import myBertModel, myTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_data(MysqlDatabase, sql):\n",
    "    df = MysqlDatabase.select_table(sql)\n",
    "    df['text'] = df['title'] + ' ' + df['excerpt'] + ' ' + df['topics']\n",
    "    df = df[['text', 'name']]\n",
    "    df.columns = ['text', 'label']\n",
    "    ##\n",
    "    df_t, df_v,= train_test_split(df, test_size = 0.1, random_state = 42, stratify = df.label)\n",
    "    df_t['type'] = 'train'\n",
    "    df_v['type'] = 'valid'\n",
    "    df = pd.concat([df_t, df_v], sort=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # 標籤存檔\n",
    "    label_df = pd.get_dummies(df.label)\n",
    "    Y = label_df.values\n",
    "    print('Shape of label tensor:', Y.shape)\n",
    "\n",
    "    label_list = list(label_df.columns)\n",
    "    label_dic = { i : label_list[i] for i in range(0, len(label_list) ) }\n",
    "    label_site = './model_output/dcard_cate_label_dic.npy'\n",
    "    np.save(label_site, label_dic)\n",
    "\n",
    "    ##\n",
    "    Y_df = pd.DataFrame(Y)\n",
    "    df = pd.concat([df, Y_df],sort = True, axis=1)\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "    return df, Y_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def seq_padding(X, padding=0):\n",
    "    L = [len(x) for x in X]\n",
    "    ML = max(L)\n",
    "    return np.array([\n",
    "        np.concatenate([x, [padding] * (ML - len(x))]) if len(x) < ML else x for x in X\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class dataGenerator:\n",
    "    def __init__(self, data, batch_size=32):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = len(self.data) // self.batch_size\n",
    "        if len(self.data) % self.batch_size != 0:\n",
    "            self.steps += 1\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idxs = list(range(len(self.data)))\n",
    "            np.random.shuffle(idxs)\n",
    "            X1, X2, Y = [], [], []\n",
    "            for i in idxs:\n",
    "                d = self.data[i]\n",
    "                text = d[0][:maxlen]\n",
    "                x1, x2 = MyTokenizer.encode(first=text)\n",
    "                y = d[1:]\n",
    "                X1.append(x1)\n",
    "                X2.append(x2)\n",
    "                Y.append(y)\n",
    "                if len(X1) == self.batch_size or i == idxs[-1]:\n",
    "                    X1 = seq_padding(X1)\n",
    "                    X2 = seq_padding(X2)\n",
    "                    Y = seq_padding(Y)\n",
    "                    yield [X1, X2], Y\n",
    "                    [X1, X2, Y] = [], [], []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ['TF_KERAS'] = '1'\n",
    "    maxlen = 100\n",
    "    pretrained_path = '/Users/jackyfu/Desktop/hwf87_git/bert_wwm/'\n",
    "    config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "    checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "    vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "    output_path = '/Users/jackyfu/Desktop/hwf87_git/Dcard_post_classification/model_output'\n",
    "    with open('config.yml', 'r') as stream:\n",
    "        myconfig = yaml.load(stream, Loader=yaml.CLoader)\n",
    "    database_username = myconfig['mysql_database']['database_username']\n",
    "    database_password = myconfig['mysql_database']['database_password']\n",
    "    database_ip       = myconfig['mysql_database']['database_ip']\n",
    "    database_name     = myconfig['mysql_database']['database_name']\n",
    "    MysqlDatabase = mysqlDatabase(database_username, database_password, database_ip, database_name)\n",
    "    sql = '''\n",
    "    SELECT df.name, dp.*\n",
    "    FROM Bigdata.dcard_posts dp\n",
    "    left join Bigdata.dcard_forums df on dp.forumid = df.id\n",
    "    WHERE 1=1\n",
    "    and df.name in ('時事', '網路購物', '股票', '美妝', '工作', '考試', '穿搭', '3C', 'Apple', '感情', \n",
    "                    '美食', '理財', '居家生活', '臺灣大學', 'YouTuber');\n",
    "    '''\n",
    "    ##\n",
    "    df, Y_df = get_data(MysqlDatabase, sql)\n",
    "    MyBertModel = myBertModel(pretrained_path, config_path, checkpoint_path, vocab_path)\n",
    "    token_dict = MyBertModel.get_token_dict()\n",
    "    model = MyBertModel.build_model(Y_df)\n",
    "    MyTokenizer = myTokenizer(token_dict)\n",
    "\n",
    "    train_data = df[df['type'] == 'train'].drop(columns=['label', 'type']).values.tolist()\n",
    "    valid_data = df[df['type'] == 'valid'].drop(columns=['label', 'type']).values.tolist()\n",
    "    \n",
    "    train_D = dataGenerator(train_data)\n",
    "    valid_D = dataGenerator(valid_data)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_D.__iter__(),\n",
    "        steps_per_epoch=len(train_D),\n",
    "        epochs=2,\n",
    "        validation_data=valid_D.__iter__(),\n",
    "        validation_steps=len(valid_D)\n",
    "    )\n",
    "    model_path = './model_output/dcard_post_cls_bert.h5'\n",
    "    model.save(model_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully select from Bigdata table\n",
      "Shape of label tensor: (16446, 15)\n",
      "(16446, 18)\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/17/dsyzw2j96ggfgmrjcsnbtz700000gn/T/ipykernel_63321/1431389716.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_t['type'] = 'train'\n",
      "/var/folders/17/dsyzw2j96ggfgmrjcsnbtz700000gn/T/ipykernel_63321/1431389716.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_v['type'] = 'valid'\n",
      "2021-09-05 19:03:48.518167: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-05 19:03:48.518492: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, None, 768)    101677056   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 768)          0           model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 15)           11535       lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 101,688,591\n",
      "Trainable params: 101,688,591\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "0729e0afaf4d65e2a91a3bdab3b4bf083879cf81e41f52fbed812722fa13cb93"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}